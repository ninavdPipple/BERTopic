{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ninavdPipple/BERTopic/blob/master/Small_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load packages and arrange right set up"
      ],
      "metadata": {
        "id": "kk6JXn6KVj8v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xTZlaIn0xGR",
        "outputId": "63337f0b-aeda-4527-f252-451cf2bfbeaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nO0TehEcdJ1",
        "outputId": "f036ac6e-a577-47dd-85a8-1f8714a2e836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.9.0)\n",
            "Requirement already satisfied: bertopic in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.23.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.33)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.5.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.1.0)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.2)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.3.1)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.15.0)\n",
            "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (0.29.37)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2023.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (23.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.3.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.37.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.1.0+cu121)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (9.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.58.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (4.9.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=0.4.1->bertopic) (0.4.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers>=0.4.1->bertopic) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n",
            "Requirement already satisfied: tomotopy in /usr/local/lib/python3.10/dist-packages (0.12.7)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tomotopy) (1.23.0)\n",
            "Requirement already satisfied: octis in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: gensim==4.2.0 in /usr/local/lib/python3.10/dist-packages (from octis) (4.2.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from octis) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from octis) (1.5.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from octis) (3.7.4)\n",
            "Requirement already satisfied: scikit-learn==1.1.0 in /usr/local/lib/python3.10/dist-packages (from octis) (1.1.0)\n",
            "Requirement already satisfied: scikit-optimize>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from octis) (0.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from octis) (3.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from octis) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy==1.23.0 in /usr/local/lib/python3.10/dist-packages (from octis) (1.23.0)\n",
            "Requirement already satisfied: libsvm in /usr/local/lib/python3.10/dist-packages (from octis) (3.23.0.4)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from octis) (2.2.5)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (from octis) (2.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from octis) (2.31.0)\n",
            "Requirement already satisfied: tomotopy in /usr/local/lib/python3.10/dist-packages (from octis) (0.12.7)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0->octis) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0->octis) (6.4.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.0->octis) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.1.0->octis) (3.3.0)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize>=0.8.1->octis) (23.12.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->octis) (8.1.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->octis) (2.8.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->octis) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->octis) (4.66.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->octis) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->octis) (2024.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->octis) (4.37.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->octis) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->octis) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->octis) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->octis) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->octis) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->octis) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->octis) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->octis) (2.1.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (0.9.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (2.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->octis) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers->octis) (6.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->octis) (2.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->octis) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->octis) (2.16.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->octis) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->octis) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->octis) (0.1.4)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->octis) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers->octis) (0.4.2)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy->octis) (0.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->octis) (1.3.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.3)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install typing_extensions --upgrade\n",
        "!pip install bertopic\n",
        "from bertopic import BERTopic\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bertopic.representation import KeyBERTInspired\n",
        "!pip install kora -q\n",
        "from kora import drive\n",
        "drive.link_nbs()\n",
        "!python -m pip install tomotopy\n",
        "!pip install octis\n",
        "from octis.dataset.dataset import Dataset\n",
        "from Evaluation_BERTopic_repo import Trainer, DataLoader, Evaluator\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "!pip install openai\n",
        "import openai\n",
        "from openai import AzureOpenAI\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', -1) # make sure to print entire messages when printed form dataframe\n",
        "import regex as re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NESIY-SihtJa"
      },
      "outputs": [],
      "source": [
        "# Connecting to GPT model\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_key=\"139ff4ea58234550972e6f5db98b30a7\",\n",
        "    api_version='2023-05-15',\n",
        "    azure_endpoint = \"https://510-openai.openai.azure.com/\"\n",
        ")\n",
        "\n",
        "deployment_name='510-chat' #This will correspond to the custom name you chose for your deployment when you deployed a model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define functions for training model"
      ],
      "metadata": {
        "id": "LQW-vuqTFcCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emojis(text):\n",
        "  # Define regex expression for emojis\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "       u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "        u\"\\U00002702-\\U000027B0\"\n",
        "        u\"\\U000024C2-\\U0001F251\"\n",
        "        u\"\\U0001f926-\\U0001f937\"\n",
        "        u\"\\U00010000-\\U0010ffff\"\n",
        "        u\"\\u2640-\\u2642\"\n",
        "        u\"\\u2600-\\u2B55\"\n",
        "        u\"\\u200d\"\n",
        "        u\"\\u23cf\"\n",
        "        u\"\\u23e9\"\n",
        "        u\"\\u231a\"\n",
        "        u\"\\ufe0f\"  # dingbats\n",
        "        u\"\\u3030\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "  # Remove emojis\n",
        "  modified_text = emoji_pattern.sub(r'.', text)\n",
        "  modified_text = re.sub(r'([\\:\\<]-?[)(|\\\\/pP3D])(?:(?=\\s))', '.', modified_text)\n",
        "  modified_text = modified_text.lstrip('.') # Remove dots at start of message that arise as a result\n",
        "\n",
        "  return modified_text\n",
        "\n",
        "# Remove sequential interpunction\n",
        "def remove_repeats(text):\n",
        "  modified_text=re.sub(r'([^\\w])\\s*([^\\w\\s])+', lambda match: '? ' if '?' in match.group() else match.group(2), text)\n",
        "\n",
        "  return modified_text"
      ],
      "metadata": {
        "id": "L5ocSpO4lyDZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from OCTIS_preprocess_repo import Preprocessing\n",
        "os.chdir(os.path.pardir)\n",
        "\n",
        "def pre_process_data(raw_data, pre_process, reformulations_path = None):\n",
        "\n",
        "  # Distinguish between reformulations and normal messages to not overwrite data\n",
        "  if reformulations_path:\n",
        "    path = reformulations_path\n",
        "  else:\n",
        "    path = f'/content/drive/MyDrive/2024'\n",
        "\n",
        "  # Pre-process data if still needed\n",
        "  if os.path.exists(f'{path}/ukraine_{pre_process}'):\n",
        "    # Obtain existing pre-processed dataset\n",
        "    dataset = Dataset('ukraine')\n",
        "    dataset.load_custom_dataset_from_folder(f'{path}/ukraine_{pre_process}')\n",
        "  else:\n",
        "    # Save required data in required format\n",
        "    raw_data['low'] =  raw_data['low'].apply(lambda x: re.sub(r'\\n',' ', str(x)))     # Remove enters within message to process messages correctly\n",
        "    raw_data['low'].to_csv(f'{path}/documents_stripped_low.csv', index=False,  encoding=\"utf-8-sig\")\n",
        "    raw_data['label'].to_csv(f'{path}/labels.csv', index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "    # Remove smileys and sequential punctuation for medium pre-processing\n",
        "    if pre_process == 'medium':\n",
        "      raw_data['medium'] = raw_data['low'].apply(remove_emojis)\n",
        "      raw_data['medium'] = raw_data['medium'].apply(remove_repeats)\n",
        "      raw_data['medium'].to_csv(f'{path}/documents_stripped_medium.csv', index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "    # Make reference to the right documents\n",
        "    docs = pre_process\n",
        "\n",
        "    # Initialize pre-processing\n",
        "    if pre_process == 'heavy':\n",
        "      preprocessor = Preprocessing(lowercase=True,\n",
        "          remove_punctuation=True,\n",
        "          punctuation=string.punctuation,\n",
        "          remove_numbers=False,\n",
        "          lemmatize=False,\n",
        "          language=\"english\",\n",
        "          split=False,\n",
        "          verbose=False,\n",
        "          save_original_indexes=True,\n",
        "          remove_stopwords_spacy=False,)\n",
        "      docs = 'medium' # Refer to the right documents\n",
        "    elif pre_process == 'full':\n",
        "      preprocessor = Preprocessing(lowercase=True,\n",
        "                remove_punctuation=True,\n",
        "                punctuation=string.punctuation,\n",
        "                remove_numbers=True,\n",
        "                lemmatize=False,\n",
        "                language=\"english\",\n",
        "                split=False,\n",
        "                verbose=False,\n",
        "                save_original_indexes=True,\n",
        "                remove_stopwords_spacy=False,)\n",
        "      docs = 'medium' # Refer to the right documents\n",
        "    elif pre_process == 'extra':\n",
        "      preprocessor = Preprocessing(lowercase=True,\n",
        "          remove_punctuation=True,\n",
        "          punctuation=string.punctuation,\n",
        "          remove_numbers=True,\n",
        "          lemmatize=True,\n",
        "          language=\"english\",\n",
        "          split=False,\n",
        "          verbose=False,\n",
        "          save_original_indexes=True,\n",
        "          remove_stopwords_spacy=False,)\n",
        "      docs = 'medium' # Refer to the right documents\n",
        "    else:\n",
        "      preprocessor = Preprocessing(lowercase=True,\n",
        "                      remove_punctuation=False,\n",
        "                      punctuation=string.punctuation,\n",
        "                      remove_numbers=False,\n",
        "                      lemmatize=False,\n",
        "                      language=\"english\",\n",
        "                      split=False,\n",
        "                      verbose=True,\n",
        "                      save_original_indexes=True,\n",
        "                      remove_stopwords_spacy=False,)\n",
        "      docs = 'medium' # Refer to the right documents\n",
        "\n",
        "    # Pre-process\n",
        "    dataset = preprocessor.preprocess_dataset(documents_path=f'{path}/documents_stripped_{docs}.csv', labels_path=f'{path}/labels.csv')\n",
        "\n",
        "    # Save the pre-processed dataset\n",
        "    dataset.save(f'{path}/ukraine_{pre_process}')\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "r1OyDowgBtU6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "def embed_messages(embedding_model, dataset, model):\n",
        "\n",
        "  # Prepare data\n",
        "  data = [\" \".join(words) for words in dataset.get_corpus()]\n",
        "\n",
        "  # Calculate embeddings\n",
        "  embeddings = embedding_model.encode(data, show_progress_bar=True)\n",
        "\n",
        "  # Prepare data\n",
        "  data = [\" \".join(words) for words in dataset.get_corpus()]\n",
        "\n",
        "  # Calculate embeddings\n",
        "  embeddings = embedding_model.encode(data, show_progress_bar=True)\n",
        "\n",
        "  # Save embeddings\n",
        "  with open(f'/content/drive/MyDrive/2024/{model}/embeddings.npy', 'wb') as f:\n",
        "      np.save(f, embeddings)\n",
        "\n",
        "  return embeddings"
      ],
      "metadata": {
        "id": "FvKwWmUhBPfl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(raw_data, pre_process, embed, model, word2vec_model):\n",
        "\n",
        "  # Pre-process data\n",
        "  dataset = pre_process_data(raw_data, pre_process)\n",
        "\n",
        "  # Embed data\n",
        "    # Pick embedder\n",
        "  if embed == 'default':\n",
        "    embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "    embedding_model.max_seq_length = 512\n",
        "  elif embed == 'advanced':\n",
        "    embedding_model = SentenceTransformer('jamesgpt1/sf_model_e5')\n",
        "  embeddings = embed_messages(embedding_model, dataset, model)\n",
        "\n",
        "  params = {\n",
        "    'embedding_model': embedding_model,\n",
        "    'verbose': True,\n",
        "    'umap_model': UMAP(n_neighbors=15, n_components=5, min_dist=0.0, low_memory = False, metric='cosine',random_state=1), # Fix UMAP model with random state\n",
        "    'hdbscan_model': HDBSCAN(min_cluster_size=10, prediction_data=True, metric='euclidean', cluster_selection_method='eom', gen_min_span_tree=True), # min cluster size by default 10\n",
        "    'vectorizer_model': CountVectorizer(stop_words=\"english\", ngram_range=(1, 2)), # default only ngram (1,1)\n",
        "    # 'representation_model': KeyBERTInspired(), # strongly influences measures depending on topic words\n",
        "  }\n",
        "\n",
        "  trainer = Trainer(dataset=f'/content/drive/MyDrive/2024/ukraine_{pre_process}',\n",
        "                  model_name=\"BERTopic\",\n",
        "                  params=params,\n",
        "                  bt_embeddings=embeddings,\n",
        "                  custom_dataset=True,\n",
        "                  verbose=False,\n",
        "                  word2vec_model=word2vec_model,\n",
        "                  semi_supervised=False,\n",
        "                  labels = raw_data['label_num'])\n",
        "  results, topic_model = trainer.train(save=f\"/content/drive/MyDrive/2024/{model}/train_results\")\n",
        "\n",
        "\n",
        "  # Save model\n",
        "  topic_model.save(f'/content/drive/MyDrive/2024/{model}/topic_model.joblib', serialization=\"pickle\")\n"
      ],
      "metadata": {
        "id": "CbrLJ97DAJ7l"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions for evaluating the model"
      ],
      "metadata": {
        "id": "LqlGUEEO3v0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtain RRI results"
      ],
      "metadata": {
        "id": "QugUMTp8WaQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.cluster import pair_confusion_matrix\n",
        "\n",
        "# Calculate RRI\n",
        "\n",
        "def get_RRI(topics, labels, leave_out = [-1]):\n",
        "  \"\"\"\n",
        "  Caluclates the refinement Rand Index score while leaving out some topics\n",
        "\n",
        "  Input:\n",
        "  topics: the refined topics\n",
        "  labels: the original labeling\n",
        "  leave_out: a  list of topic numbers to hold out. By default only exclude outliers\n",
        "\n",
        "  Returns the Refinement Rand Index\n",
        "  \"\"\"\n",
        "  # Exclude the specified topics\n",
        "  labels = labels[~topics.isin(leave_out)]\n",
        "  topics = topics[~topics.isin(leave_out)]\n",
        "\n",
        "  # Measure on refinement; inspired on Rand Index\n",
        "  contingency = pair_confusion_matrix(labels, topics)\n",
        "  RRI = (contingency[1][1]+contingency[1][0]+contingency[0][0])/ (contingency[1][1]+contingency[1][0]+contingency[0][0]+contingency[1][1])\n",
        "  return RRI"
      ],
      "metadata": {
        "id": "bAW5MGJfWgLQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtain coherence results"
      ],
      "metadata": {
        "id": "_ju7KqZcZzGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coherence(data, document_info, topic_model, embeddings, dataset, word2vec_model):\n",
        "  doc_ids = range(len(data))\n",
        "  documents = pd.DataFrame({\"Document\": data,\n",
        "                            \"ID\": doc_ids,\n",
        "                            'Class':  document_info['Topic']})\n",
        "  bertopic_evaluator =  Evaluator(documents, embeddings, topic_model = topic_model, name = 'BERTopic', dataset =dataset, word2vec_model=word2vec_model, verbose = False)\n",
        "  scores = bertopic_evaluator.score(save = None)\n",
        "  return scores"
      ],
      "metadata": {
        "id": "IwKGrErC54Of"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Obtain SRA results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2HttuPi2Ve3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "def balanced_subsample(n, raw_data):\n",
        "    n_categories = raw_data['label'].nunique()\n",
        "    counts = raw_data.label.value_counts().sort_values()\n",
        "    sorted_labels = counts.index.tolist()\n",
        "\n",
        "    n_remaining = n\n",
        "    subsample = []\n",
        "\n",
        "    for label, count in counts.items():\n",
        "        samples_per_category = round(n_remaining/n_categories) # Calculate the new number of samples per category\n",
        "        if count < samples_per_category:\n",
        "            sample_size =  count\n",
        "        else:\n",
        "            sample_size = samples_per_category\n",
        "\n",
        "        label_ids = np.where(raw_data['label'] ==  label)[0]\n",
        "        sample_ids = random.sample(label_ids.tolist(), sample_size)\n",
        "        subsample.extend(sample_ids)\n",
        "        n_remaining -= sample_size\n",
        "        n_categories -= 1\n",
        "\n",
        "    return raw_data.low.iloc[subsample]\n",
        "\n",
        "def create_reformulations(raw_data, n, path):\n",
        "  # Returns and saves reformulated messages\n",
        "  prompt_format = \"\"\"\n",
        "  I have a Telegram message that looks as follows: [MESSAGE]\n",
        "\n",
        "  Based on the information above, please rewrite the Telegram message while keeping the pronoun the same in the following format:\n",
        "  Message: <reformulation>\n",
        "  \"\"\"\n",
        "  subsample = balanced_subsample(n, raw_data)\n",
        "  reformulations = pd.DataFrame({'Original': subsample.to_numpy(), 'Reformulation': np.repeat('', n)})\n",
        "  reformulations.set_index(np.array(subsample.index), inplace=True)\n",
        "\n",
        "  delay_in_seconds=1 # Delay in between subsequent prompts to avoid RateLimitError of OpenAI\n",
        "\n",
        "\n",
        "  for i, message in enumerate(reformulations.Original):\n",
        "    prompt = prompt_format.replace('[MESSAGE]', message)\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}]\n",
        "    kwargs = {\"model\": deployment_name, \"messages\": messages}\n",
        "\n",
        "    response = client.chat.completions.create(**kwargs)\n",
        "    reformulation = response.choices[0].message.content.strip().replace(\"Message: \", \"\")\n",
        "\n",
        "    # Remove remaining introduction\n",
        "    reformulation = reformulation.replace(\"<Reformulation>\",\"\").strip()\n",
        "    reformulation = reformulation.replace(\"<reformulation>\",\"\")\n",
        "    reformulation = reformulation.replace(\"<Message>\",\"\")\n",
        "    reformulation = reformulation.replace(\"<message>\",\"\")\n",
        "    reformulation = reformulation.replace(\"Reformulation:\",\"\")\n",
        "    reformulation = reformulation.replace(\"reformulation:\",\"\")\n",
        "    reformulation = reformulation.replace(\"Message:\",\"\")\n",
        "    reformulation = reformulation.replace(\"message:\",\"\")\n",
        "\n",
        "    reformulations.Reformulation.iloc[i] = reformulation\n",
        "    time.sleep(delay_in_seconds)\n",
        "\n",
        "  # Store because of expensive recalculation\n",
        "  if not os.path.exists(f'{path}'):\n",
        "    os.makedirs(f'{path}')\n",
        "  reformulations.to_csv(path, index=True, encoding=\"utf-8-sig\")\n",
        "\n",
        "  return reformulations\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_SRA(topic_model, document_info, pre_process, reformulations = None, raw_data = None, n=20, save_to ='/content/drive/MyDrive/2024/reformulations'):\n",
        "  # Either input reformulations or raw_data and n\n",
        "  # Calculates the SRA score\n",
        "\n",
        "  # Obtain reformulated messages\n",
        "  if reformulations is None:\n",
        "    refomulations = create_reformulations(raw_data, n, path = f'{save_to}.csv')\n",
        "\n",
        "  # Pre-process reformulations\n",
        "  test_data = reformulations.rename(columns ={'Reformulation':'low'})\n",
        "  test_data['label'] = np.repeat('', n) # Create fake label data in order to be able to apply pre-processing\n",
        "  test_data = pre_process_data(test_data, pre_process, reformulations_path = save_to)\n",
        "  test_data = test_data.get_corpus()\n",
        "  test_data = [\" \".join(words) for words in test_data]\n",
        "\n",
        "  # Obtain results for reformulations\n",
        "  reformulation_topics, reformulation_dist = topic_model.transform(test_data) # OUPTPUT DIFFERS WITH WHICH OTHER MESSAGES A REFORMULATION IS PROCESSED\n",
        "\n",
        "  # Calculate SRA\n",
        "  cos_sim = np.diag(cosine_similarity(reformulation_dist, topic_model.probabilities_[reformulations.index]))\n",
        "  SRA = np.mean(cos_sim)\n",
        "\n",
        "  # Backhand calculations\n",
        "  SRA_info = reformulations.copy()\n",
        "  SRA_info['Original topic'] = document_info.Topic.iloc[reformulations.index]\n",
        "  SRA_info['Reformulation topic']=  reformulation_topics\n",
        "  SRA_info['cos_sim'] = cos_sim\n",
        "\n",
        "  return SRA, SRA_info\n",
        "\n",
        "def SRA_results(raw_data, document_info, topic_model, pre_process, repeats =1, existig_reformulations = True, n=20): # Boolean if saved reformulations can be used\n",
        "  SRAs = []\n",
        "\n",
        "  for run in range(repeats):\n",
        "    path  = f'/content/drive/MyDrive/2024/reformulations/{run}'\n",
        "    if existig_reformulations:\n",
        "      reformulations = pd.read_csv(f'{path}.csv', index_col =0)\n",
        "      SRA, SRA_info = calculate_SRA(topic_model, document_info, pre_process, reformulations = reformulations, save_to = path)\n",
        "    else:\n",
        "      SRA, SRA_info = calculate_SRA(topic_model, document_info, pre_process, raw_data = raw_data, n=n, save_to = path)\n",
        "    SRAs.append(SRA)\n",
        "\n",
        "  # Show insights of last run\n",
        "  return SRAs, SRA_info"
      ],
      "metadata": {
        "id": "Yq9ap4V9sqCX"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "_Emg1sCdFpgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "raw_data = pd.read_csv('/content/drive/MyDrive/2024/raw_data.csv', encoding=\"utf-8-sig\")"
      ],
      "metadata": {
        "id": "IUgAKm3JxDnf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load word2vec model\n",
        "from gensim.models import KeyedVectors\n",
        "word2vec_model = KeyedVectors.load('/content/drive/MyDrive/2024/word2vec_model.kv')"
      ],
      "metadata": {
        "id": "6V_-FbHXJI4N"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(pre_process,embed, raw_data, word2vec_model, existig_reformulations = True):\n",
        "  # Pick model\n",
        "  if pre_process == 'low' and embed == 'default':\n",
        "    model = 'LD'\n",
        "  elif pre_process == 'medium' and embed == 'default':\n",
        "    model = 'MD'\n",
        "  elif pre_process == 'low' and embed == 'advanced':\n",
        "    model = 'LA'\n",
        "  elif pre_process == 'medium' and embed == 'advanced':\n",
        "    model = 'MA'\n",
        "  elif pre_process == 'heavy' and embed == 'default':\n",
        "    model = 'HD'\n",
        "  elif pre_process == 'full' and embed == 'default':\n",
        "    model = 'FD'\n",
        "  elif pre_process == 'extra' and embed == 'default':\n",
        "    model = 'ED'\n",
        "\n",
        "  # Check if model has been trained already\n",
        "  new_model = not os.path.exists(f\"/content/drive/MyDrive/2024/{model}\")\n",
        "  if new_model:\n",
        "    os.makedirs(f\"/content/drive/MyDrive/2024/{model}\")\n",
        "    train_model(raw_data, pre_process = pre_process, embed = embed, model = model, word2vec_model=word2vec_model)\n",
        "    print('Finished training '+model)\n",
        "  else:\n",
        "    print('Loading '+model)\n",
        "\n",
        "  # Load pre-processed dataset\n",
        "  dataset = Dataset('ukraine')\n",
        "  dataset.load_custom_dataset_from_folder(f'/content/drive/MyDrive/2024/ukraine_{pre_process}')\n",
        "  list_data = dataset.get_corpus()\n",
        "  data = [\" \".join(words) for words in list_data]\n",
        "\n",
        "  # Load embeddings\n",
        "  with open(f'/content/drive/MyDrive/2024/{model}/embeddings.npy', 'rb') as f:\n",
        "    embeddings = np.load(f)\n",
        "\n",
        "  # Load model\n",
        "  topic_model = BERTopic.load(f'/content/drive/MyDrive/2024/{model}/topic_model.joblib')\n",
        "\n",
        "  # Obtain results\n",
        "  document_info = topic_model.get_document_info(data)\n",
        "\n",
        "  # Get metrics\n",
        "  RRI = get_RRI(document_info['Topic'], raw_data['label'])\n",
        "  coherence_scores = get_coherence(data, document_info, topic_model, embeddings,dataset, word2vec_model)\n",
        "  DBCV = topic_model.hdbscan_model.relative_validity_\n",
        "\n",
        "  # Save the values of all metrics\n",
        "  scores = coherence_scores\n",
        "  scores['RRI'] = RRI\n",
        "  scores[ 'DBCV'] = DBCV\n",
        "  SRAs, SRA_info = SRA_results(raw_data, document_info, topic_model, pre_process, repeats =1, existig_reformulations = existig_reformulations, n=20)\n",
        "  scores['SRA'] = np.mean(SRAs)\n",
        "  with open(f\"/content/drive/MyDrive/2024/{model}/results.json\", \"w\") as f:\n",
        "      json.dump(scores, f)\n",
        "  print(scores)\n",
        "\n",
        "  return topic_model, document_info, SRAs, SRA_info\n"
      ],
      "metadata": {
        "id": "SvaogtAI4hE5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_embeddings = False\n",
        "\n",
        "for pre_process in ['extra']:\n",
        "  for embed in ['default']:\n",
        "    run_pipeline(pre_process,embed, raw_data, word2vec_model, existig_reformulations = not create_embeddings)\n",
        "    create_embeddings = False # At most once needed to create the embeddings for testing multiple models"
      ],
      "metadata": {
        "id": "LqMMwPLfy7Mv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445,
          "referenced_widgets": [
            "80a7501120b04e4b9bbd4cb84e14657d",
            "bc1572dfa58047fba2c7a7a2767331c3",
            "1bd0c233ab7b4873b4b6f510540b77aa",
            "8308ed6abf5a493fa8919e9c567927a5",
            "2f575a50c5ee4f79bd8ae21f0f0826cd",
            "3f276c23ed024b5baf80015f1a5f178f",
            "1b48d42b482b4080a583743ed8eccbf8",
            "bcc63a7ead5743aa8a6903f06f2774f7",
            "fb70ed623c7947ef85e295852d555def",
            "9ac7fb696af04acea1b0b5569b65da05",
            "bbd95abf48c646f5be4798e733d900a3",
            "b41a5fc1a235440aa5a3b9425b268ed7",
            "261da0b64f19400d94a8bc67d5796bb3",
            "8db6cf2bd74b4312a4d8b7694e1d60f2",
            "8d4b4d873a7546f5964ab81304b34b0c",
            "51c3b640adf34622a4993f043ad56553",
            "39c5de7cefd0406ca87f7f76c3fce661",
            "fa069eb313d24a698dcb8994bda23c3d",
            "14741fd96d954d1c9af185793501efed",
            "41b0ec2d275f41c59b7752a6e000a530",
            "9e51976d05c14a0b94dfc7ba699d6c8b",
            "abc19c8ec5f44474b8d9f8258a84fdf9",
            "3ddbc63a100242fc98b7da876f353609",
            "e6be8b8e54b045189b77e21a58f8bca6",
            "a4fd307551ca4075a44fe1e92dc51d48",
            "6ba76ff3d14949c288f9fa1a416179db",
            "ebc995f340804d02a9f39e389dd95596",
            "7bc2be7081374b27b896b09a6d680966",
            "c24aca1319444ac6beeb1c04267fff8d",
            "35e0b23210e846e29abcf86cae36fbd4",
            "819c1faca8e548b5be0c4babd71e8abb",
            "8176b0d7680d4c45afe27f5f13e099da",
            "bde5be394c1e4e3280f47bc2732a2802"
          ]
        },
        "outputId": "590b03cc-01b9-4817-f333-49412e952825"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4522/4522 [01:22<00:00, 54.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created vocab\n",
            "6497\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/142 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80a7501120b04e4b9bbd4cb84e14657d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/142 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b41a5fc1a235440aa5a3b9425b268ed7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-21 14:31:54,152 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
            "2024-02-21 14:32:06,499 - BERTopic - Dimensionality - Completed ✓\n",
            "2024-02-21 14:32:06,501 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
            "2024-02-21 14:32:08,376 - BERTopic - Cluster - Completed ✓\n",
            "2024-02-21 14:32:08,388 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
            "2024-02-21 14:32:09,170 - BERTopic - Representation - Completed ✓\n",
            "2024-02-21 14:32:13,633 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished training ED\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ddbc63a100242fc98b7da876f353609"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-02-21 14:32:28,276 - BERTopic - Dimensionality - Reducing dimensionality of input embeddings.\n",
            "2024-02-21 14:32:30,355 - BERTopic - Dimensionality - Completed ✓\n",
            "2024-02-21 14:32:30,359 - BERTopic - Clustering - Approximating new points with `hdbscan_model`\n",
            "2024-02-21 14:32:30,377 - BERTopic - Probabilities - Start calculation of probabilities with HDBSCAN\n",
            "2024-02-21 14:32:30,456 - BERTopic - Probabilities - Completed ✓\n",
            "2024-02-21 14:32:30,462 - BERTopic - Cluster - Completed ✓\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'npmi': 0.13277869506774295, 'we': 0.1797294633687982, 'diversity': 0.41847826086956524, 'RRI': 0.013209062100724072, 'DBCV': 0.19728483513805795, 'SRA': 0.8354165046132179}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data in right format"
      ],
      "metadata": {
        "id": "2PJAT2kx3EhZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJV_dOAJESFs"
      },
      "outputs": [],
      "source": [
        "# # Load data\n",
        "# raw_data = pd.read_excel('/content/drive/MyDrive/messages_2023_list.xlsx')\n",
        "\n",
        "# # Remove enters in label names\n",
        "# raw_data['label'] =  raw_data['label'].apply(lambda x: re.sub(r'\\n','', str(x)))\n",
        "\n",
        "# # Create class numbers for each label for semi-supervised learning\n",
        "# label_to_num = {k: v for v, k in enumerate(pd.Series(raw_data['label']).unique())}\n",
        "# raw_data['label_num'] = raw_data['label'].map(label_to_num)\n",
        "\n",
        "# # Remove urls\n",
        "# raw_data['text'] = raw_data['text'].apply(lambda x: re.sub(r'\\(https[^\\)]*\\)',' <URL> ', str(x))) # Remove based on brackets\n",
        "# raw_data['text'] = raw_data['text'].apply(lambda x: re.sub(r'https[\\S]*','<URL>', str(x))) # Remove based on followed by a space or enter\n",
        "\n",
        "# # Remove any remaining Ukrainian text\n",
        "# raw_data['low'] =  raw_data['text'].apply(lambda x: re.sub(r'\\p{IsCyrillic}','', str(x)))\n",
        "\n",
        "# # Save required data\n",
        "# raw_data.to_csv('/content/drive/MyDrive/2024/raw_data.csv', index=False, encoding=\"utf-8-sig\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN70_dvTE8VZ"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import display, HTML\n",
        "\n",
        "# def pretty_print(df):\n",
        "#   # Prints DataFrames in a neat format\n",
        "#   return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\")))\n",
        "\n",
        "# # Print examples from pre-processing\n",
        "\n",
        "# raw_data_examples = pd.read_excel('/content/drive/MyDrive/messages_2023_list_old.xlsx')\n",
        "\n",
        "# examples = raw_data_examples[['text', 'label']].iloc[[565,1448,456]]\n",
        "\n",
        "# pretty_print(examples)\n",
        "\n",
        "# # Remove any remaining Ukrainian text\n",
        "# raw_data_examples['low'] =  raw_data_examples['text'].apply(lambda x: re.sub(r'\\p{IsCyrillic}','', str(x)))\n",
        "\n",
        "# pretty_print(pd.DataFrame(raw_data_examples[['text', 'low']].iloc[2266]).transpose().rename(columns={'text':'Original', 'low': 'Pre-processed'}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SfSG8rCe3zY"
      },
      "outputs": [],
      "source": [
        "# import gensim.downloader as api\n",
        "\n",
        "# word2vec_model = api.load('word2vec-google-news-300')\n",
        "# word2vec_model.save('/content/drive/MyDrive/2024/word2vec_model.kv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect data"
      ],
      "metadata": {
        "id": "mr_F3GLX3bAg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5dtn9N3Jq4W"
      },
      "outputs": [],
      "source": [
        "# Analyze data\n",
        "\n",
        "# # Overview of categories\n",
        "# plt.figure().set_figheight(7)\n",
        "# sns.countplot(y = 'label', data=raw_data, order = raw_data['label'].value_counts().index)\n",
        "# plt.title('Messages per category')\n",
        "# plt.xlabel('Amount of messages')\n",
        "# plt.ylabel('Label')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfbQe5SCyGee"
      },
      "outputs": [],
      "source": [
        "# #%%\n",
        "# words = [re.sub('[^a-z]','',word.lower()) for message in list_data for word in message] # Remove punctuation and digits and lowercase all words\n",
        "# no_stops = [word for word in words if word not in stopwords.words('english')] # Exclude stopwords\n",
        "# counts = Counter(no_stops)\n",
        "# print(counts.most_common(50))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBD6LtALSfeI"
      },
      "outputs": [],
      "source": [
        "# # Analyse lenght of messages\n",
        "# lengths = [len(message) for message in list_data]\n",
        "# print('Max lenght:', max(lengths))\n",
        "# print('Min lenght:', min(lengths))\n",
        "# longest_messages = (-np.array(lengths)).argsort()[:10]\n",
        "# sns.histplot(lengths)\n",
        "# plt.title('Distribution of message sizes')\n",
        "# plt.xlabel('Number of words')\n",
        "# plt.ylabel('Amount of messages')\n",
        "# plt.xticks(np.arange(0,550,50))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1rjck2Hvy_e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "d37d639a-8665-46b3-d9c3-c5cd52e375f5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'embedding_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-a53631544523>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Tokenize sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_model' is not defined"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "tokenizer = embedding_model.tokenizer\n",
        "\n",
        "# Tokenize sentences\n",
        "tokenized_messages = tokenizer(data, padding=True, truncation=False, return_tensors='pt')\n",
        "\n",
        "# Check how many messages cut-off by truncation of SBERT\n",
        "\n",
        "num_tokens = torch.sum(tokenized_messages['input_ids'] > 0, dim=1)\n",
        "# sns.histplot(num_tokens)\n",
        "num_tokens = pd.Series(num_tokens)\n",
        "bins = [0,256,512,1000] # Default truncation is after 256 and can be adjusted to max 512\n",
        "print(num_tokens.value_counts(bins=bins))\n",
        "\n",
        "# Truncation has barely any result. Also because urls blanked and digits removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwDZ4d0wWfbS"
      },
      "outputs": [],
      "source": [
        "# documents = pd.DataFrame({\"Document\": data,\n",
        "#                           \"ID\": doc_ids,\n",
        "#                           'Class':  raw_data['label']})\n",
        "\n",
        "# baseline_evaluator =  Evaluator(documents, embeddings, topic_model = BERTopic(umap_model= umap_model), name = 'Original labeling', dataset =dataset, word2vec_model=word2vec_model)\n",
        "\n",
        "# baseline_evaluator.score(save= f\"/content/drive/MyDrive/2024/baseline_results\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giYKQlMigT33"
      },
      "outputs": [],
      "source": [
        "# # Remove multiple occurences of the same character\n",
        "# # from Tweettokenizer\n",
        "#     pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "#     return pattern.sub(r\"\\1\\1\\1\", text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_cluster(num):\n",
        "  # Check specific cluster\n",
        "  return (document_info['Document'][document_info['Topic']== num])"
      ],
      "metadata": {
        "id": "rPXqK1LxNHR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Briefly inspect Introdcution effect\n",
        "\n",
        "# example_reformulations = pd.read_csv('/content/drive/MyDrive/2024/reformulations.csv', index_col =0)\n",
        "# SRA, SRA_info = calculate_SRA(topic_model,reformulations = example_reformulations)\n",
        "# print(SRA_info.cos_sim.iloc[-1])\n",
        "\n",
        "# cleaned =  example_reformulations.copy()\n",
        "# alternative = cleaned.Reformulation.iloc[-1].replace('<Message>\\n', '')\n",
        "# cleaned.Reformulation.iloc[-1] = alternative\n",
        "# SRA, SRA_info = calculate_SRA(topic_model,reformulations = cleaned)\n",
        "# SRA_info.cos_sim.iloc[-1]"
      ],
      "metadata": {
        "id": "nF1JZN2ELPce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Found topic for reformulation:')\n",
        "print(topic_model.get_topic_info()[['Topic', 'Representation']].iloc[[5+1]].to_string())\n",
        "print(check_cluster(5))\n",
        "\n",
        "print('\\n Reformulation in outlier: ')\n",
        "print(topic_model.get_topic_info()[['Topic', 'Representation']].iloc[[4+1]].to_string())\n",
        "print(check_cluster(4))\n",
        "\n",
        "print('\\n Confuse topics:')\n",
        "print(topic_model.get_topic_info()[['Topic', 'Representation']].iloc[[2+1,56+1]].to_string())"
      ],
      "metadata": {
        "id": "dYlwTBdcJqDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeFDL2dZmcFw"
      },
      "outputs": [],
      "source": [
        "#%%\n",
        "\n",
        "# Analyse results\n",
        "print(topic_model.get_topic_info())\n",
        "print(document_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THoWsFjKyylJ"
      },
      "outputs": [],
      "source": [
        "# from OpenAI_BERTopic_repo import OpenAI\n",
        "\n",
        "# summarization_prompt = \"\"\"\n",
        "# This is a list of texts where each collection of texts describe a topic. After each collection of texts, a summary that captures the most important content of the texts in the collections is provided.\n",
        "# ---\n",
        "# Topic:\n",
        "# Sample texts from this topic:\n",
        "# - Traditional diets in most cultures were primarily plant-based with a little meat on top, but with the rise of industrial style meat production and factory farming, meat has become a staple food.\n",
        "# - Meat, but especially beef, is the worst food in terms of emissions.\n",
        "# - Eating meat doesn't make you a bad person, not eating meat doesn't make you a good one.\n",
        "\n",
        "# Keywords: meat beef eat eating emissions steak food health processed chicken\n",
        "# Summary: Meat has become a bigger component of our diets. Eating meat is harmful for the enviroment.\n",
        "# ---\n",
        "# Topic:\n",
        "# Sample texts from this topic:\n",
        "# - I have ordered the product weeks ago but it still has not arrived!\n",
        "# - The website mentions that it only takes a couple of days to deliver but I still have not received mine.\n",
        "# - I got a message stating that I received the monitor but that is not true!\n",
        "# - It took a month longer to deliver than was advised...\n",
        "\n",
        "# Keywords: deliver weeks product shipping long delivery received arrived arrive week\n",
        "# Summary: Some packages take a long time to get delivered. False claims about the delivery of packages are being made.\n",
        "# ---\n",
        "# Topic:\n",
        "# Sample texts from this topic:\n",
        "# [DOCUMENTS]\n",
        "# Keywords: [KEYWORDS]\n",
        "# Summary:\"\"\"\n",
        "\n",
        "# representation_model= OpenAI(client,model = deployment_name, prompt = summarization_prompt, nr_docs=20, delay_in_seconds=3)\n",
        "# representation_model.extract_topics(topic_model, documents.rename(columns={'Class':'Topic'}), topic_model.c_tf_idf_, topic_model.topic_representations_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCaL17hiCu8G"
      },
      "outputs": [],
      "source": [
        "# Select cluster to analyse\n",
        "cluster_num = 36"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-C2_c7RrdUF"
      },
      "outputs": [],
      "source": [
        "from OpenAI_BERTopic_repo import OpenAI\n",
        "\n",
        "summarization_chat_prompt = \"\"\"\n",
        "I have a topic that is described by the following keywords: [KEYWORDS]\n",
        "In this topic, the following documents are a small but representative subset of all documents in the topic:\n",
        "[DOCUMENTS]\n",
        "\n",
        "Based on the information above, please write a summary that captures the most important content of this topic in the following format:\n",
        "topic: <summary>\n",
        "\"\"\"\n",
        "\n",
        "representation_model = OpenAI(client, model=deployment_name, chat=True, prompt=summarization_chat_prompt, nr_docs=20, delay_in_seconds=3)\n",
        "representation_model.extract_topics(topic_model, documents[documents['Class']==cluster_num].rename(columns={'Class':'Topic'}), topic_model.c_tf_idf_.getrow(cluster_num), {cluster_num:topic_model.topic_representations_[cluster_num]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LobMg5JouO0T"
      },
      "outputs": [],
      "source": [
        "print(topic_model.get_topic_freq().head(11))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWgVr-rPGVeG"
      },
      "outputs": [],
      "source": [
        "# Overview of cluster sizes\n",
        "sns.barplot(y = 'Count', x = 'Topic', data=topic_model.get_topic_freq().iloc[1:])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAox2c5pH0Mg"
      },
      "outputs": [],
      "source": [
        "# Check biggest cluster\n",
        "print(document_info['Document'][document_info['Topic']== 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZoOyXlKTlyc"
      },
      "outputs": [],
      "source": [
        "# Analyze clusters of large text messages\n",
        "\n",
        "print(raw_data['text'].iloc[longest_messages])\n",
        "print(document_info['Topic'].iloc[longest_messages])\n",
        "\n",
        "# Check specific cluster\n",
        "print('Longest cluster:', document_info['Top_n_words'].iloc[longest_messages[0]])\n",
        "print(document_info['Document'][document_info['Topic']== document_info['Topic'].iloc[longest_messages[0]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOf-zjtXuSaE"
      },
      "outputs": [],
      "source": [
        "fig = topic_model.visualize_topics()\n",
        "fig.write_html(\"inter.html\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66OjoHixuVEc"
      },
      "outputs": [],
      "source": [
        "heatmap = topic_model.visualize_heatmap()\n",
        "heatmap.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_5Rw9giucyx"
      },
      "outputs": [],
      "source": [
        "# Check specific cluster\n",
        "print(check_cluster(74))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgI-qIOpusRE"
      },
      "outputs": [],
      "source": [
        "#%%\n",
        "\n",
        "# Check if not focussing on marker tokens\n",
        "# Could potentionally check with tf-idf score\n",
        "# Now because of preprocessing punctuation is removed, so markers not this specific anymore\n",
        "\n",
        "pers_topics = pd.concat([document_info['Topic'],raw_data['text'].str.contains('<PERSON>')],axis=1)\n",
        "freq_pers = pers_topics.groupby(['Topic'], as_index=False).mean()\n",
        "sns.barplot(x = 'Topic', y= 'text', data=freq_pers, color='b')\n",
        "plt.title('<PERSON> marker')\n",
        "plt.ylabel('Percetage contains <PERSON>')\n",
        "plt.show()\n",
        "\n",
        "url_topics = document_info['Topic'][raw_data['text'].str.contains('<URL>')]\n",
        "sns.histplot(url_topics, binwidth=1)\n",
        "plt.title('<URL> marker')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6BIjeaz8ofw"
      },
      "outputs": [],
      "source": [
        "# Get matrix with for every word the importance for that topic and the corresponding words\n",
        "topic_term_matrix = topic_model.c_tf_idf_.toarray()\n",
        "words = topic_model.vectorizer_model.get_feature_names_out()\n",
        "\n",
        "# Get the column corresponding to person\n",
        "person_col = np.where(words=='person')[0]\n",
        "\n",
        "# Get for each topic the ranking on how important person is\n",
        "person_importance = np.where(np.argsort(-topic_term_matrix)==person_col)[1]\n",
        "\n",
        "# Get the ranking for the topic where it's most important (exclude the outliers)\n",
        "max_importance = np.min(person_importance[1:])\n",
        "print(max_importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muUxAl0pFzXd"
      },
      "outputs": [],
      "source": [
        "KK_topics = pd.concat([document_info['Topic'],raw_data['text'].str.contains(' KK ')],axis=1)\n",
        "freq_KK = KK_topics.groupby(['Topic'], as_index=False).mean()\n",
        "sns.barplot(x = 'Topic', y= 'text', data=freq_KK, color='b')\n",
        "plt.title('KK')\n",
        "plt.ylabel('Percetage contains KK')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftn5GcixvNPj"
      },
      "outputs": [],
      "source": [
        "#%%\n",
        "\n",
        "# Ditribution over topics\n",
        "\n",
        "topic_distr, _ = topic_model.approximate_distribution(data, window=8, stride=4)\n",
        "topic_model.visualize_distribution(topic_distr[0], custom_labels=True)\n",
        "\n",
        "# Maybe nice for long messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vPro2MRwYiU"
      },
      "outputs": [],
      "source": [
        "instance = 3121\n",
        "\n",
        "# Calculate the topic distributions on a token-level\n",
        "topic_distr, topic_token_distr = topic_model.approximate_distribution(data, calculate_tokens=True)\n",
        "\n",
        "# Visualize the token-level distributions\n",
        "topic_model.visualize_approximate_distribution(data[instance], topic_token_distr[instance])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbu5mt1yw94J"
      },
      "outputs": [],
      "source": [
        "topics_per_class = topic_model.topics_per_class(raw_data['text'], classes=raw_data['label'])\n",
        "\n",
        "fig = topic_model.visualize_topics_per_class(topics_per_class, top_n_topics=None)\n",
        "# fig.write_html(\"class.html\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv_ce_o9_eTd"
      },
      "outputs": [],
      "source": [
        "raw_data[['text', 'label']][document_info.Topic==79]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJuCNyNr0bdK"
      },
      "outputs": [],
      "source": [
        "hierarchical_topics = topic_model.hierarchical_topics(raw_data['text'])\n",
        "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3dFQ72tB56q"
      },
      "outputs": [],
      "source": [
        "# Assign an original label to topics if more than a threshold percentage of the messages in the topic originate from that label\n",
        "\n",
        "threshold = 0.7\n",
        "raw_data['topic']= document_info['Top_n_words']\n",
        "clustered_only = raw_data[document_info['Topic']!=-1] # Exclude outliers\n",
        "\n",
        "# Count the number of occurences of each label within each topic\n",
        "label_count = clustered_only[['topic', 'label']].groupby(['topic', 'label']).size().reset_index(name='count')\n",
        "\n",
        "# Obtain the frequency how much of the topic originated from which label\n",
        "label_count['freq'] = label_count.groupby(['topic'])['count'].apply(lambda x: x / x.sum()) # DataFrame containing per topic the distribution over the original labels\n",
        "\n",
        "# Say a topic is a refinement if more that the threshold originated from the same label\n",
        "clear_refined = label_count[label_count['freq']>=threshold][['label', 'freq', 'topic']]\n",
        "print(str(len(clear_refined)), ' topics originate clearly from refinement on labeling')\n",
        "print(clear_refined.groupby(['label'])['label', 'topic'].apply(print))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lio4tzzRj6fA"
      },
      "outputs": [],
      "source": [
        "# Get topics that are not from a parcticular label\n",
        "\n",
        "potential_new = label_count[label_count['freq']<threshold][['label', 'freq', 'topic']]\n",
        "covered_topics = clear_refined['topic'].tolist()\n",
        "\n",
        "# Exclude refinement topics\n",
        "potential_new = potential_new[~potential_new['topic'].isin(covered_topics)]\n",
        "\n",
        "# Order topics based on being least certain to be part of the refinement\n",
        "potential_new = potential_new.groupby('topic')['freq'].max().reset_index(name='certainty') # Get the assignment score to the label it was most likely to occur\n",
        "potential_new = potential_new.sort_values('certainty')\n",
        "print(potential_new)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPDAN5kNIQrx"
      },
      "outputs": [],
      "source": [
        "document_info['Document'][document_info['Top_n_words'] ==  potential_new['topic'].iloc[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8hyEPhKR5b7"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import silhouette_score\n",
        "\n",
        "# # Obtain the umap embeddings\n",
        "# umap_embeddings = topic_model.umap_model.transform(embeddings)\n",
        "\n",
        "# # Exclude outliers\n",
        "# umap_embeddings = umap_embeddings[document_info['Topic']!=-1]\n",
        "# clustering = document_info['Topic'][document_info['Topic']!=-1]\n",
        "\n",
        "# # Calculate silhouette score\n",
        "# print(silhouette_score(umap_embeddings, clustering))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP5vvMJviwQR2BIz27Z9euL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "80a7501120b04e4b9bbd4cb84e14657d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bc1572dfa58047fba2c7a7a2767331c3",
              "IPY_MODEL_1bd0c233ab7b4873b4b6f510540b77aa",
              "IPY_MODEL_8308ed6abf5a493fa8919e9c567927a5"
            ],
            "layout": "IPY_MODEL_2f575a50c5ee4f79bd8ae21f0f0826cd"
          }
        },
        "bc1572dfa58047fba2c7a7a2767331c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f276c23ed024b5baf80015f1a5f178f",
            "placeholder": "​",
            "style": "IPY_MODEL_1b48d42b482b4080a583743ed8eccbf8",
            "value": "Batches: 100%"
          }
        },
        "1bd0c233ab7b4873b4b6f510540b77aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc63a7ead5743aa8a6903f06f2774f7",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb70ed623c7947ef85e295852d555def",
            "value": 142
          }
        },
        "8308ed6abf5a493fa8919e9c567927a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac7fb696af04acea1b0b5569b65da05",
            "placeholder": "​",
            "style": "IPY_MODEL_bbd95abf48c646f5be4798e733d900a3",
            "value": " 142/142 [02:00&lt;00:00,  5.30it/s]"
          }
        },
        "2f575a50c5ee4f79bd8ae21f0f0826cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f276c23ed024b5baf80015f1a5f178f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b48d42b482b4080a583743ed8eccbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcc63a7ead5743aa8a6903f06f2774f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb70ed623c7947ef85e295852d555def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ac7fb696af04acea1b0b5569b65da05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd95abf48c646f5be4798e733d900a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b41a5fc1a235440aa5a3b9425b268ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_261da0b64f19400d94a8bc67d5796bb3",
              "IPY_MODEL_8db6cf2bd74b4312a4d8b7694e1d60f2",
              "IPY_MODEL_8d4b4d873a7546f5964ab81304b34b0c"
            ],
            "layout": "IPY_MODEL_51c3b640adf34622a4993f043ad56553"
          }
        },
        "261da0b64f19400d94a8bc67d5796bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39c5de7cefd0406ca87f7f76c3fce661",
            "placeholder": "​",
            "style": "IPY_MODEL_fa069eb313d24a698dcb8994bda23c3d",
            "value": "Batches: 100%"
          }
        },
        "8db6cf2bd74b4312a4d8b7694e1d60f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14741fd96d954d1c9af185793501efed",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41b0ec2d275f41c59b7752a6e000a530",
            "value": 142
          }
        },
        "8d4b4d873a7546f5964ab81304b34b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e51976d05c14a0b94dfc7ba699d6c8b",
            "placeholder": "​",
            "style": "IPY_MODEL_abc19c8ec5f44474b8d9f8258a84fdf9",
            "value": " 142/142 [02:03&lt;00:00,  5.46it/s]"
          }
        },
        "51c3b640adf34622a4993f043ad56553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39c5de7cefd0406ca87f7f76c3fce661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa069eb313d24a698dcb8994bda23c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14741fd96d954d1c9af185793501efed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b0ec2d275f41c59b7752a6e000a530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e51976d05c14a0b94dfc7ba699d6c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abc19c8ec5f44474b8d9f8258a84fdf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ddbc63a100242fc98b7da876f353609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6be8b8e54b045189b77e21a58f8bca6",
              "IPY_MODEL_a4fd307551ca4075a44fe1e92dc51d48",
              "IPY_MODEL_6ba76ff3d14949c288f9fa1a416179db"
            ],
            "layout": "IPY_MODEL_ebc995f340804d02a9f39e389dd95596"
          }
        },
        "e6be8b8e54b045189b77e21a58f8bca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc2be7081374b27b896b09a6d680966",
            "placeholder": "​",
            "style": "IPY_MODEL_c24aca1319444ac6beeb1c04267fff8d",
            "value": "Batches: 100%"
          }
        },
        "a4fd307551ca4075a44fe1e92dc51d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35e0b23210e846e29abcf86cae36fbd4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_819c1faca8e548b5be0c4babd71e8abb",
            "value": 1
          }
        },
        "6ba76ff3d14949c288f9fa1a416179db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8176b0d7680d4c45afe27f5f13e099da",
            "placeholder": "​",
            "style": "IPY_MODEL_bde5be394c1e4e3280f47bc2732a2802",
            "value": " 1/1 [00:01&lt;00:00,  1.34s/it]"
          }
        },
        "ebc995f340804d02a9f39e389dd95596": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bc2be7081374b27b896b09a6d680966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c24aca1319444ac6beeb1c04267fff8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e0b23210e846e29abcf86cae36fbd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819c1faca8e548b5be0c4babd71e8abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8176b0d7680d4c45afe27f5f13e099da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bde5be394c1e4e3280f47bc2732a2802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}